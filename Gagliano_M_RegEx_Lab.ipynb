{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6 style=\"text-align: center;\">Completed by: Michael Gagliano on 9/6/2018</h6>\n",
    "<h6 style=\"text-align: center;\">\"K-State Honor Code \"On my honor, as a student, I have neither given nor received unauthorized aid on this academic work.</h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expression & Python\n",
    "\n",
    "- A natural processing tool for text search and manipulation\n",
    "- Essential for text analytics (e.g., web crawling, text mining), but difficult to master\n",
    "- Learned though trial and error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources: You must review this ...\n",
    "\n",
    "**You can find a comprehensive list of regular expression patterns and examples http://scraping.pro/regex-expressions/**\n",
    "\n",
    "**Online regular expression tester https://regexr.com/**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\\d matches digit 1 3 5 in 1st 3d 5th\n",
    "\\D+ matches nondigits Harley road in 2500 Harley road\n",
    "\\w matches A 1 2 9 6 _ in A-12-96_\n",
    "\\W matches nonword character - - , in A-12-96\n",
    "\n",
    "[0-9] Match any digit; same as [0123456789]\n",
    "[a-z] Match any lowercase ASCII letter\n",
    "[A-Z] Match any uppercase ASCII letter\n",
    "[a-zA-Z0-9] Match any of the above\n",
    "[^0-9] Match anything other than a digit\n",
    "\n",
    ".*+?^&$()[]{}\\|/ Characters that go for special meaning unless backslashed ‘\\’ \n",
    "\\^, \\$, \\\\ match  ^, $, \\\n",
    "\n",
    "^a matches only first a in abcadaef.\n",
    ".$ matches f in abcdef\n",
    ".\\b matches c in abc; \\b. matches a in abc\n",
    "a.c matches abc, asc or adc\n",
    "abc(def|xyz) matches abcdef or abcxyz\n",
    "(abc) matches abc in 34abcdef\\t\n",
    "\n",
    "\\d(?:abc) captures 4abc in 34abcdef but abc being a passive capture group, while 4 is in active one.\n",
    "[a-zA-Z0-9] matches any letter or digit\n",
    "[^a-d4-6] matches any character except a, b, c or d, or 4,5 or 6\n",
    "\n",
    "a{2,4} matches only aaaa in aaaaa\n",
    "a{2,} matches aaaaa in aaaaa ... Greedy!\n",
    "\n",
    "(?= ) matches a group after your main expression without including it in the result.\n",
    "(?<= ) matches a group before your main expression without including it in the result.\n",
    "(?! ) Specifies a group that can not match after your main expression (ie. if it matches, the result is discarded).\n",
    "(?<!= ) Specifies a group that can not match before your main expression (ie. if it matches, the result is discarded).\n",
    "\n",
    "\\w+(?=\\.) matches sleep, ill and Oops in We sleep. The man is ill. Oops.!\n",
    "\\b\\w+(?!\\.)\\b matches We, The, man and is in We sleep. The man is ill. Oops.!\n",
    "(?<=DDR2)\\s+\\w+ matches 2GB in DDR2 2MB\n",
    "(?<!=20)\\d{2}\\b matches 45, 76 in 1945 2012 1876 2002\n",
    "\n",
    "Sources:\n",
    "http://scraping.pro/regex-expressions/\n",
    "http://regexr.com/v1/\n",
    "http://www.tutorialspoint.com/python/python_reg_expressions.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing regular expression package\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re.findall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'dog']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first comma contains your search term, the second comma contains text data\n",
    "re.findall('dog', 'dog cat dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('cat', 'dog cat dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'cat']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"cat\",\"A cat and a cat can't be friends.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://regexr.com/\n",
    "\n",
    "text = '''\n",
    "        Welcome to RegExr v2.0 by gskinner.com!\n",
    "\n",
    "        Edit the Expression & Text to see matches. Roll over matches or the expression for details. \n",
    "        Undo mistakes with ctrl-z. Save & Share expressions with friends or the Community. \n",
    "        A full Reference & Help is available in the Library, or watch the video Tutorial.\n",
    "\n",
    "        Sample text for testing:\n",
    "        abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "        0123456789 _+-.,!@#$%^&*();\\/|<>\"'\n",
    "        12345 -98.7 3.141 .6180 9,000 +42\n",
    "        555.123.4567\t+1-(800)-555-2468\n",
    "        foo@demo.net\tbar.ba@test.co.uk\n",
    "        www.demo.com\thttp://foo.co.uk/\n",
    "        http://regexr.com/foo.html?q=bar\n",
    "        https://www.payment.com\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\d matches digit 1 3 5 in 1st 3d 5th\n",
    "\\D+ matches nondigits Harley road in 2500 Harley road\n",
    "\\w matches A 1 2 9 6 _ in A-12-96_\n",
    "\\W matches nonword character - - , in A-12-96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '9',\n",
       " '8',\n",
       " '7',\n",
       " '3',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '6',\n",
       " '1',\n",
       " '8',\n",
       " '0',\n",
       " '9',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '4',\n",
       " '2',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '1',\n",
       " '8',\n",
       " '0',\n",
       " '0',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '2',\n",
       " '4',\n",
       " '6',\n",
       " '8']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find any digit\n",
    "re.findall('\\d', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n        Welcome to RegExr v',\n",
       " '.',\n",
       " ' by gskinner.com!\\n\\n        Edit the Expression & Text to see matches. Roll over matches or the expression for details. \\n        Undo mistakes with ctrl-z. Save & Share expressions with friends or the Community. \\n        A full Reference & Help is available in the Library, or watch the video Tutorial.\\n\\n        Sample text for testing:\\n        abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ\\n        ',\n",
       " ' _+-.,!@#$%^&*();\\\\/|<>\"\\'\\n        ',\n",
       " ' -',\n",
       " '.',\n",
       " ' ',\n",
       " '.',\n",
       " ' .',\n",
       " ' ',\n",
       " ',',\n",
       " ' +',\n",
       " '\\n        ',\n",
       " '.',\n",
       " '.',\n",
       " '\\t+',\n",
       " '-(',\n",
       " ')-',\n",
       " '-',\n",
       " '\\n        foo@demo.net\\tbar.ba@test.co.uk\\n        www.demo.com\\thttp://foo.co.uk/\\n        http://regexr.com/foo.html?q=bar\\n        https://www.payment.com\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find any non-digit\n",
    "\n",
    "re.findall('\\D+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W',\n",
       " 'e',\n",
       " 'l',\n",
       " 'c',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " 't',\n",
       " 'o',\n",
       " 'R',\n",
       " 'e',\n",
       " 'g',\n",
       " 'E',\n",
       " 'x',\n",
       " 'r',\n",
       " 'v',\n",
       " '2',\n",
       " '0',\n",
       " 'b',\n",
       " 'y',\n",
       " 'g',\n",
       " 's',\n",
       " 'k',\n",
       " 'i',\n",
       " 'n',\n",
       " 'n',\n",
       " 'e',\n",
       " 'r',\n",
       " 'c',\n",
       " 'o',\n",
       " 'm',\n",
       " 'E',\n",
       " 'd',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'E',\n",
       " 'x',\n",
       " 'p',\n",
       " 'r',\n",
       " 'e',\n",
       " 's',\n",
       " 's',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n',\n",
       " 'T',\n",
       " 'e',\n",
       " 'x',\n",
       " 't',\n",
       " 't',\n",
       " 'o',\n",
       " 's',\n",
       " 'e',\n",
       " 'e',\n",
       " 'm',\n",
       " 'a',\n",
       " 't',\n",
       " 'c',\n",
       " 'h',\n",
       " 'e',\n",
       " 's',\n",
       " 'R',\n",
       " 'o',\n",
       " 'l',\n",
       " 'l',\n",
       " 'o',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " 'm',\n",
       " 'a',\n",
       " 't',\n",
       " 'c',\n",
       " 'h',\n",
       " 'e',\n",
       " 's',\n",
       " 'o',\n",
       " 'r',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'e',\n",
       " 'x',\n",
       " 'p',\n",
       " 'r',\n",
       " 'e',\n",
       " 's',\n",
       " 's',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " 'd',\n",
       " 'e',\n",
       " 't',\n",
       " 'a',\n",
       " 'i',\n",
       " 'l',\n",
       " 's',\n",
       " 'U',\n",
       " 'n',\n",
       " 'd',\n",
       " 'o',\n",
       " 'm',\n",
       " 'i',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'k',\n",
       " 'e',\n",
       " 's',\n",
       " 'w',\n",
       " 'i',\n",
       " 't',\n",
       " 'h',\n",
       " 'c',\n",
       " 't',\n",
       " 'r',\n",
       " 'l',\n",
       " 'z',\n",
       " 'S',\n",
       " 'a',\n",
       " 'v',\n",
       " 'e',\n",
       " 'S',\n",
       " 'h',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " 'e',\n",
       " 'x',\n",
       " 'p',\n",
       " 'r',\n",
       " 'e',\n",
       " 's',\n",
       " 's',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n',\n",
       " 's',\n",
       " 'w',\n",
       " 'i',\n",
       " 't',\n",
       " 'h',\n",
       " 'f',\n",
       " 'r',\n",
       " 'i',\n",
       " 'e',\n",
       " 'n',\n",
       " 'd',\n",
       " 's',\n",
       " 'o',\n",
       " 'r',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'C',\n",
       " 'o',\n",
       " 'm',\n",
       " 'm',\n",
       " 'u',\n",
       " 'n',\n",
       " 'i',\n",
       " 't',\n",
       " 'y',\n",
       " 'A',\n",
       " 'f',\n",
       " 'u',\n",
       " 'l',\n",
       " 'l',\n",
       " 'R',\n",
       " 'e',\n",
       " 'f',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " 'H',\n",
       " 'e',\n",
       " 'l',\n",
       " 'p',\n",
       " 'i',\n",
       " 's',\n",
       " 'a',\n",
       " 'v',\n",
       " 'a',\n",
       " 'i',\n",
       " 'l',\n",
       " 'a',\n",
       " 'b',\n",
       " 'l',\n",
       " 'e',\n",
       " 'i',\n",
       " 'n',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'L',\n",
       " 'i',\n",
       " 'b',\n",
       " 'r',\n",
       " 'a',\n",
       " 'r',\n",
       " 'y',\n",
       " 'o',\n",
       " 'r',\n",
       " 'w',\n",
       " 'a',\n",
       " 't',\n",
       " 'c',\n",
       " 'h',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'v',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " 'o',\n",
       " 'T',\n",
       " 'u',\n",
       " 't',\n",
       " 'o',\n",
       " 'r',\n",
       " 'i',\n",
       " 'a',\n",
       " 'l',\n",
       " 'S',\n",
       " 'a',\n",
       " 'm',\n",
       " 'p',\n",
       " 'l',\n",
       " 'e',\n",
       " 't',\n",
       " 'e',\n",
       " 'x',\n",
       " 't',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " 't',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '_',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '9',\n",
       " '8',\n",
       " '7',\n",
       " '3',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '6',\n",
       " '1',\n",
       " '8',\n",
       " '0',\n",
       " '9',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '4',\n",
       " '2',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '1',\n",
       " '8',\n",
       " '0',\n",
       " '0',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '2',\n",
       " '4',\n",
       " '6',\n",
       " '8',\n",
       " 'f',\n",
       " 'o',\n",
       " 'o',\n",
       " 'd',\n",
       " 'e',\n",
       " 'm',\n",
       " 'o',\n",
       " 'n',\n",
       " 'e',\n",
       " 't',\n",
       " 'b',\n",
       " 'a',\n",
       " 'r',\n",
       " 'b',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'c',\n",
       " 'o',\n",
       " 'u',\n",
       " 'k',\n",
       " 'w',\n",
       " 'w',\n",
       " 'w',\n",
       " 'd',\n",
       " 'e',\n",
       " 'm',\n",
       " 'o',\n",
       " 'c',\n",
       " 'o',\n",
       " 'm',\n",
       " 'h',\n",
       " 't',\n",
       " 't',\n",
       " 'p',\n",
       " 'f',\n",
       " 'o',\n",
       " 'o',\n",
       " 'c',\n",
       " 'o',\n",
       " 'u',\n",
       " 'k',\n",
       " 'h',\n",
       " 't',\n",
       " 't',\n",
       " 'p',\n",
       " 'r',\n",
       " 'e',\n",
       " 'g',\n",
       " 'e',\n",
       " 'x',\n",
       " 'r',\n",
       " 'c',\n",
       " 'o',\n",
       " 'm',\n",
       " 'f',\n",
       " 'o',\n",
       " 'o',\n",
       " 'h',\n",
       " 't',\n",
       " 'm',\n",
       " 'l',\n",
       " 'q',\n",
       " 'b',\n",
       " 'a',\n",
       " 'r',\n",
       " 'h',\n",
       " 't',\n",
       " 't',\n",
       " 'p',\n",
       " 's',\n",
       " 'w',\n",
       " 'w',\n",
       " 'w',\n",
       " 'p',\n",
       " 'a',\n",
       " 'y',\n",
       " 'm',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'c',\n",
       " 'o',\n",
       " 'm']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find any word character and underscore\n",
    "re.findall('\\w', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n        ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '.',\n",
       " ' ',\n",
       " ' ',\n",
       " '.',\n",
       " '!\\n\\n        ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' & ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '. ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '. \\n        ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '-',\n",
       " '. ',\n",
       " ' & ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '. \\n        ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' & ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ', ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '.\\n\\n        ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ':\\n        ',\n",
       " ' ',\n",
       " '\\n        ',\n",
       " ' ',\n",
       " '+-.,!@#$%^&*();\\\\/|<>\"\\'\\n        ',\n",
       " ' -',\n",
       " '.',\n",
       " ' ',\n",
       " '.',\n",
       " ' .',\n",
       " ' ',\n",
       " ',',\n",
       " ' +',\n",
       " '\\n        ',\n",
       " '.',\n",
       " '.',\n",
       " '\\t+',\n",
       " '-(',\n",
       " ')-',\n",
       " '-',\n",
       " '\\n        ',\n",
       " '@',\n",
       " '.',\n",
       " '\\t',\n",
       " '.',\n",
       " '@',\n",
       " '.',\n",
       " '.',\n",
       " '\\n        ',\n",
       " '.',\n",
       " '.',\n",
       " '\\t',\n",
       " '://',\n",
       " '.',\n",
       " '.',\n",
       " '/\\n        ',\n",
       " '://',\n",
       " '.',\n",
       " '/',\n",
       " '.',\n",
       " '?',\n",
       " '=',\n",
       " '\\n        ',\n",
       " '://',\n",
       " '.',\n",
       " '.',\n",
       " '\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matches any non-word character\n",
    "\n",
    "re.findall('\\W+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0123456789',\n",
       " '12345',\n",
       " '98',\n",
       " '141',\n",
       " '6180',\n",
       " '000',\n",
       " '42',\n",
       " '555',\n",
       " '123',\n",
       " '4567',\n",
       " '800',\n",
       " '555',\n",
       " '2468']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anything starts with a number\n",
    "re.findall('\\d\\w+', text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0-9] Match any digit; same as [0123456789]\n",
    "[a-z] Match any lowercase ASCII letter\n",
    "[A-Z] Match any uppercase ASCII letter\n",
    "[a-zA-Z0-9] Match any of the above\n",
    "[^0-9] Match anything other than a digit\n",
    "[a-zA-Z0-9] matches any letter or digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '9',\n",
       " '8',\n",
       " '7',\n",
       " '3',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '6',\n",
       " '1',\n",
       " '8',\n",
       " '0',\n",
       " '9',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '4',\n",
       " '2',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '1',\n",
       " '8',\n",
       " '0',\n",
       " '0',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '2',\n",
       " '4',\n",
       " '6',\n",
       " '8']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match any digit\n",
    "re.findall('[0-9]', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0123456789',\n",
       " '12345',\n",
       " '98',\n",
       " '141',\n",
       " '6180',\n",
       " '000',\n",
       " '42',\n",
       " '555',\n",
       " '123',\n",
       " '4567',\n",
       " '800',\n",
       " '555',\n",
       " '2468']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any complete number\n",
    "re.findall('[0-9]\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elcome',\n",
       " 'to',\n",
       " 'eg',\n",
       " 'xr',\n",
       " 'v',\n",
       " 'by',\n",
       " 'gskinner',\n",
       " 'com',\n",
       " 'dit',\n",
       " 'the',\n",
       " 'xpression',\n",
       " 'ext',\n",
       " 'to',\n",
       " 'see',\n",
       " 'matches',\n",
       " 'oll',\n",
       " 'over',\n",
       " 'matches',\n",
       " 'or',\n",
       " 'the',\n",
       " 'expression',\n",
       " 'for',\n",
       " 'details',\n",
       " 'ndo',\n",
       " 'mistakes',\n",
       " 'with',\n",
       " 'ctrl',\n",
       " 'z',\n",
       " 'ave',\n",
       " 'hare',\n",
       " 'expressions',\n",
       " 'with',\n",
       " 'friends',\n",
       " 'or',\n",
       " 'the',\n",
       " 'ommunity',\n",
       " 'full',\n",
       " 'eference',\n",
       " 'elp',\n",
       " 'is',\n",
       " 'available',\n",
       " 'in',\n",
       " 'the',\n",
       " 'ibrary',\n",
       " 'or',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'video',\n",
       " 'utorial',\n",
       " 'ample',\n",
       " 'text',\n",
       " 'for',\n",
       " 'testing',\n",
       " 'abcdefghijklmnopqrstuvwxyz',\n",
       " 'foo',\n",
       " 'demo',\n",
       " 'net',\n",
       " 'bar',\n",
       " 'ba',\n",
       " 'test',\n",
       " 'co',\n",
       " 'uk',\n",
       " 'www',\n",
       " 'demo',\n",
       " 'com',\n",
       " 'http',\n",
       " 'foo',\n",
       " 'co',\n",
       " 'uk',\n",
       " 'http',\n",
       " 'regexr',\n",
       " 'com',\n",
       " 'foo',\n",
       " 'html',\n",
       " 'q',\n",
       " 'bar',\n",
       " 'https',\n",
       " 'www',\n",
       " 'payment',\n",
       " 'com']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any word starting with a lowercase letter\n",
    "\n",
    "re.findall('[a-z]+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome',\n",
       " 'RegExr',\n",
       " 'Edit',\n",
       " 'Expression',\n",
       " 'Text',\n",
       " 'Roll',\n",
       " 'Undo',\n",
       " 'Save',\n",
       " 'Share',\n",
       " 'Community',\n",
       " 'Reference',\n",
       " 'Help',\n",
       " 'Library',\n",
       " 'Tutorial',\n",
       " 'Sample',\n",
       " 'ABCDEFGHIJKLMNOPQRSTUVWXYZ']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any word starting with a uppercase letter\n",
    "re.findall('[A-Z]\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome',\n",
       " 'to',\n",
       " 'RegExr',\n",
       " 'v2',\n",
       " 'by',\n",
       " 'gskinner',\n",
       " 'com',\n",
       " 'Edit',\n",
       " 'the',\n",
       " 'Expression',\n",
       " 'Text',\n",
       " 'to',\n",
       " 'see',\n",
       " 'matches',\n",
       " 'Roll',\n",
       " 'over',\n",
       " 'matches',\n",
       " 'or',\n",
       " 'the',\n",
       " 'expression',\n",
       " 'for',\n",
       " 'details',\n",
       " 'Undo',\n",
       " 'mistakes',\n",
       " 'with',\n",
       " 'ctrl',\n",
       " 'Save',\n",
       " 'Share',\n",
       " 'expressions',\n",
       " 'with',\n",
       " 'friends',\n",
       " 'or',\n",
       " 'the',\n",
       " 'Community',\n",
       " 'full',\n",
       " 'Reference',\n",
       " 'Help',\n",
       " 'is',\n",
       " 'available',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Library',\n",
       " 'or',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'video',\n",
       " 'Tutorial',\n",
       " 'Sample',\n",
       " 'text',\n",
       " 'for',\n",
       " 'testing',\n",
       " 'abcdefghijklmnopqrstuvwxyz',\n",
       " 'ABCDEFGHIJKLMNOPQRSTUVWXYZ',\n",
       " 'foo',\n",
       " 'demo',\n",
       " 'net',\n",
       " 'bar',\n",
       " 'ba',\n",
       " 'test',\n",
       " 'co',\n",
       " 'uk',\n",
       " 'www',\n",
       " 'demo',\n",
       " 'com',\n",
       " 'http',\n",
       " 'foo',\n",
       " 'co',\n",
       " 'uk',\n",
       " 'http',\n",
       " 'regexr',\n",
       " 'com',\n",
       " 'foo',\n",
       " 'html',\n",
       " 'bar',\n",
       " 'https',\n",
       " 'www',\n",
       " 'payment',\n",
       " 'com']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any word starting with either a lowercase letter or an uppercase letter\n",
    "\n",
    "re.findall('[a-zA-Z]\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome',\n",
       " 'to',\n",
       " 'RegExr',\n",
       " 'v2',\n",
       " '0',\n",
       " 'by',\n",
       " 'gskinner',\n",
       " 'com',\n",
       " 'Edit',\n",
       " 'the',\n",
       " 'Expression',\n",
       " 'Text',\n",
       " 'to',\n",
       " 'see',\n",
       " 'matches',\n",
       " 'Roll',\n",
       " 'over',\n",
       " 'matches',\n",
       " 'or',\n",
       " 'the',\n",
       " 'expression',\n",
       " 'for',\n",
       " 'details',\n",
       " 'Undo',\n",
       " 'mistakes',\n",
       " 'with',\n",
       " 'ctrl',\n",
       " 'z',\n",
       " 'Save',\n",
       " 'Share',\n",
       " 'expressions',\n",
       " 'with',\n",
       " 'friends',\n",
       " 'or',\n",
       " 'the',\n",
       " 'Community',\n",
       " 'A',\n",
       " 'full',\n",
       " 'Reference',\n",
       " 'Help',\n",
       " 'is',\n",
       " 'available',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Library',\n",
       " 'or',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'video',\n",
       " 'Tutorial',\n",
       " 'Sample',\n",
       " 'text',\n",
       " 'for',\n",
       " 'testing',\n",
       " 'abcdefghijklmnopqrstuvwxyz',\n",
       " 'ABCDEFGHIJKLMNOPQRSTUVWXYZ',\n",
       " '0123456789',\n",
       " '12345',\n",
       " '98',\n",
       " '7',\n",
       " '3',\n",
       " '141',\n",
       " '6180',\n",
       " '9',\n",
       " '000',\n",
       " '42',\n",
       " '555',\n",
       " '123',\n",
       " '4567',\n",
       " '1',\n",
       " '800',\n",
       " '555',\n",
       " '2468',\n",
       " 'foo',\n",
       " 'demo',\n",
       " 'net',\n",
       " 'bar',\n",
       " 'ba',\n",
       " 'test',\n",
       " 'co',\n",
       " 'uk',\n",
       " 'www',\n",
       " 'demo',\n",
       " 'com',\n",
       " 'http',\n",
       " 'foo',\n",
       " 'co',\n",
       " 'uk',\n",
       " 'http',\n",
       " 'regexr',\n",
       " 'com',\n",
       " 'foo',\n",
       " 'html',\n",
       " 'q',\n",
       " 'bar',\n",
       " 'https',\n",
       " 'www',\n",
       " 'payment',\n",
       " 'com']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anything above\n",
    "\n",
    "re.findall('[a-zA-Z0-9]+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Welcome',\n",
       " ' to',\n",
       " ' RegExr',\n",
       " ' v2',\n",
       " '.0',\n",
       " ' by',\n",
       " ' gskinner',\n",
       " '.com',\n",
       " ' Edit',\n",
       " ' the',\n",
       " ' Expression',\n",
       " ' Text',\n",
       " ' to',\n",
       " ' see',\n",
       " ' matches',\n",
       " ' Roll',\n",
       " ' over',\n",
       " ' matches',\n",
       " ' or',\n",
       " ' the',\n",
       " ' expression',\n",
       " ' for',\n",
       " ' details',\n",
       " ' Undo',\n",
       " ' mistakes',\n",
       " ' with',\n",
       " ' ctrl',\n",
       " '-z',\n",
       " ' Save',\n",
       " ' Share',\n",
       " ' expressions',\n",
       " ' with',\n",
       " ' friends',\n",
       " ' or',\n",
       " ' the',\n",
       " ' Community',\n",
       " ' A',\n",
       " ' full',\n",
       " ' Reference',\n",
       " ' Help',\n",
       " ' is',\n",
       " ' available',\n",
       " ' in',\n",
       " ' the',\n",
       " ' Library',\n",
       " ' or',\n",
       " ' watch',\n",
       " ' the',\n",
       " ' video',\n",
       " ' Tutorial',\n",
       " ' Sample',\n",
       " ' text',\n",
       " ' for',\n",
       " ' testing',\n",
       " ' abcdefghijklmnopqrstuvwxyz',\n",
       " ' ABCDEFGHIJKLMNOPQRSTUVWXYZ',\n",
       " ' 0123456789',\n",
       " ' _',\n",
       " ' 12345',\n",
       " '-98',\n",
       " '.7',\n",
       " ' 3',\n",
       " '.141',\n",
       " '.6180',\n",
       " ' 9',\n",
       " ',000',\n",
       " '+42',\n",
       " ' 555',\n",
       " '.123',\n",
       " '.4567',\n",
       " '+1',\n",
       " '(800',\n",
       " '-555',\n",
       " '-2468',\n",
       " ' foo',\n",
       " '@demo',\n",
       " '.net',\n",
       " '\\tbar',\n",
       " '.ba',\n",
       " '@test',\n",
       " '.co',\n",
       " '.uk',\n",
       " ' www',\n",
       " '.demo',\n",
       " '.com',\n",
       " '\\thttp',\n",
       " '/foo',\n",
       " '.co',\n",
       " '.uk',\n",
       " ' http',\n",
       " '/regexr',\n",
       " '.com',\n",
       " '/foo',\n",
       " '.html',\n",
       " '?q',\n",
       " '=bar',\n",
       " ' https',\n",
       " '/www',\n",
       " '.payment',\n",
       " '.com']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anything starting with non-digit\n",
    "re.findall('[^0-9]\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['        Welcome to RegExr v2.0 by gskinner.com',\n",
       " '        Edit the Expression & Text to see matches. Roll over matches or the expression for details',\n",
       " '        Undo mistakes with ctrl-z. Save & Share expressions with friends or the Community',\n",
       " '        A full Reference & Help is available in the Library, or watch the video Tutorial',\n",
       " '        Sample text for testing',\n",
       " '        abcdefghijklmnopqrstuvwxyz',\n",
       " '        foo@demo.net\\tbar.ba@test.co.uk',\n",
       " '        www.demo.com\\thttp://foo.co.uk',\n",
       " '        http://regexr.com/foo.html?q=bar',\n",
       " '        https://www.payment.com']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any row containing a lowercase letter\n",
    "re.findall('.*[a-z]\\w+', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(?=  )** Matches **a group** **after** your main expression without including it in the result.\n",
    "\n",
    "**(?<=  )** Matches **a group** **before** your main expression without including it in the result.\n",
    "\n",
    "http://regexr.com/v1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome',\n",
       " 'RegExr',\n",
       " 'Edit',\n",
       " 'Expression',\n",
       " 'Text',\n",
       " 'Roll',\n",
       " 'Undo',\n",
       " 'Save',\n",
       " 'Share',\n",
       " 'Community',\n",
       " 'A',\n",
       " 'Reference',\n",
       " 'Help',\n",
       " 'Library',\n",
       " 'Tutorial',\n",
       " 'Sample',\n",
       " 'ABCDEFGHIJKLMNOPQRSTUVWXYZ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regular english words starting with an uppercase letter only\n",
    "# \\w Matches any word character (alphanumeric & underscore).\n",
    "\n",
    "re.findall('(?=[A-Z])\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elcome',\n",
       " 'egExr',\n",
       " 'dit',\n",
       " 'xpression',\n",
       " 'ext',\n",
       " 'oll',\n",
       " 'ndo',\n",
       " 'ave',\n",
       " 'hare',\n",
       " 'ommunity',\n",
       " 'eference',\n",
       " 'elp',\n",
       " 'ibrary',\n",
       " 'utorial',\n",
       " 'ample',\n",
       " 'BCDEFGHIJKLMNOPQRSTUVWXYZ']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regular english words starting with an uppercase letter only\n",
    "re.findall('(?<=[A-Z])\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@#$%^&*();\\\\/|<>\"\\'', '@demo.net\\tbar.ba@test.co.uk']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find everything after @\n",
    "re.findall('(?=@).+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo', 'test']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the alphabetical word after @\n",
    "re.findall('(?<=@)\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#regular words only (without non-alphabetical characters) starting with @  ... \n",
    "#because there is no alphabetical word starting with @\n",
    "re.findall('(?=@)\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo.co.uk/', 'regexr.com/foo.html?q=bar']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anything after http://\n",
    "re.findall('(?<=http://).+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'regexr']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the alphabetical word after http://\n",
    "re.findall('(?<=http://)\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.payment.com']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anything after https://\n",
    "re.findall('(?<=https://).+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://foo.co.uk/',\n",
       " 'http://regexr.com/foo.html?q=bar',\n",
       " 'https://www.payment.com']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anything after http:// or https://\n",
    "# | Equivalent of \"or\". Matches the full expression before or after the |.\n",
    "\n",
    "re.findall(\"(?=http://).+|(?=https://).+\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = re.findall(\"(?=http://).+|(?=https://).+\", text)\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('url.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@mike', '@Cernovich', '@michaelmalice']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# below is a tweet ... I would like to extract those users mentioned in the tweet ... challenging\n",
    "x = '''\n",
    "        RT @mike: what's up? @Cernovich @michaelmalice https://t.co/5XkEG9S7jG\n",
    "'''\n",
    "    \n",
    "re.findall('(?<=@)\\w+', x) #Does not include @ prior to handle\n",
    "re.findall('(@\\w+)', x) #Does include grouped words with @ handle included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goodday', 'goodfriday', 'analytics']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# below is a tweet ... I would like to extract all the hashtags in the tweet ... challenging\n",
    "x = '''\n",
    "        RT @mike: what's up #goodday, #goodfriday, #analytics, see you guys @Cernovich @michaelmalice https://t.co/5XkEG9S7jG\n",
    "'''\n",
    "    \n",
    "re.findall('(?<=#)\\w+', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#goodday', '#goodfriday', '#analytics']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('(#\\w+)', x) #Does a better job at including # with each tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@mike', '#big', '#bigdata', '#iot', '@Cernovich', '@michaelmalice', '#ibm']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# below is a tweet ... I would like to extract hashtags and users mentioned in the tweet ... challenging\n",
    "x = '''\n",
    "RT @mike: #big data is great #bigdata #iot @Cernovich @michaelmalice #ibm visit for latest reports\n",
    "'''\n",
    "\n",
    "re.findall(\"([#,@]\\w+)\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "When you need a regular expression, you would post your questions on or search **Stackoverflow**. Below is an example. I needed a regular expression to extract all urls and searched the site. http://stackoverflow.com/questions/6883049/regex-to-find-urls-in-string-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://foo.co.uk/',\n",
       " 'http://regexr.com/foo.html?q=bar',\n",
       " 'https://www.payment.com']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all urls\n",
    "re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "http://www.bbc.com/travel/story/20151207-sicilys-secret-chocolate-obsession\n",
    "http://www.bbc.com/travel/story/20151113-destinations-that-are-so-magical-they-hardly-seem-real\n",
    "http://www.bbc.com/travel/story/20150408-bhutans-dark-secret-to-happiness\n",
    "http://www.bbc.com/news/technology-35175263\n",
    "http://www.bbc.com/news/technology-35074007\n",
    "http://www.bbc.com/news/technology-35175265\n",
    "http://www.bbc.com/news/entertainment-arts-35178865\n",
    "http://www.bbc.com/news/entertainment-arts-35178921\n",
    "http://www.bbc.com/news/entertainment-arts-35177842\n",
    "http://www.cnn.com/2015/12/25/politics/donald-trump-yiddish-festival-schlonged/index.html\n",
    "http://www.cnn.com/2015/12/24/politics/donald-trump-golf-scotland-aberdeen/index.html\n",
    "http://www.cnn.com/2015/12/25/us/warm-christmas/index.html\n",
    "http://money.cnn.com/2015/12/24/technology/norad-santa-tracker/\n",
    "http://www.bbc.com/sport/0/football/35182965\n",
    "http://www.bbc.com/sport/0/football/35139938\n",
    "http://www.bbc.com/sport/0/football/35139941\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.bbc.com/news/technology-35175263',\n",
       " 'http://www.bbc.com/news/technology-35074007',\n",
       " 'http://www.bbc.com/news/technology-35175265']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find bbc technology related urls only\n",
    "re.findall('.*news\\/technology\\-\\d{8}', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.bbc.com/travel/story/20151207',\n",
       " 'http://www.bbc.com/travel/story/20151113',\n",
       " 'http://www.bbc.com/travel/story/20150408']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find travel related urls only\n",
    "\n",
    "re.findall('.*travel.+', text) #Pulls all articles with Travel including the article titles\n",
    "\n",
    "#or\n",
    "\n",
    "re.findall('.*travel\\/story\\/\\d{8}.+', text) #Even more specific to ensure calling specific URLS\n",
    "\n",
    "#or\n",
    "\n",
    "re.findall('.*travel\\/story\\/\\d{8}', text) #More specific on how data is called, doesn't include full article URL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.bbc.com/travel/story/20151207',\n",
       " 'http://www.bbc.com/travel/story/20151113',\n",
       " 'http://www.bbc.com/travel/story/20150408']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find BBC articles only\n",
    "\n",
    "re.findall('.*bbc\\.com\\/travel\\/story\\/\\d{8}', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.bbc.com/news/entertainment-arts-35178865',\n",
       " 'http://www.bbc.com/news/entertainment-arts-35178921',\n",
       " 'http://www.bbc.com/news/entertainment-arts-35177842']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find entertainment related urls only\n",
    "re.findall('.*news\\/entertainment-arts-\\d{8}', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.bbc.com/news/technology-35175263',\n",
       " 'http://www.bbc.com/news/technology-35074007',\n",
       " 'http://www.bbc.com/news/technology-35175265',\n",
       " 'http://money.cnn.com/2015/12/24/technology/norad-santa-tracker/']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find bbc or cnn technology related urls only\n",
    "\n",
    "re.findall('.*technology.+', text) #Not a very specific filter, but in this instance it works with the small dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.bbc.com/news/technology-35175263',\n",
       " 'http://www.bbc.com/news/technology-35074007',\n",
       " 'http://www.bbc.com/news/technology-35175265']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find bbc technology related urls only\n",
    "re.findall('.*news\\/technology.*', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.bbc.com/sport/0/football/35182965',\n",
       " 'http://www.bbc.com/sport/0/football/35139938',\n",
       " 'http://www.bbc.com/sport/0/football/35139941']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find football related urls only\n",
    "re.findall('.*+\\/sport\\/football.+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.bbc.com/news/technology-35175263',\n",
       " 'http://www.bbc.com/news/technology-35074007',\n",
       " 'http://www.bbc.com/news/technology-35175265',\n",
       " 'http://money.cnn.com/2015/12/24/technology/norad-santa-tracker/',\n",
       " 'http://www.bbc.com/sport/0/football/35182965',\n",
       " 'http://www.bbc.com/sport/0/football/35139938',\n",
       " 'http://www.bbc.com/sport/0/football/35139941']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# both technology and football\n",
    "re.findall('.+\\/sport\\/0\\/football\\/\\d{8}|.*\\/technology.*', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re.sub \n",
    "\n",
    "- a regular expression operator to substibute strings\n",
    "- http://www.tutorialspoint.com/python/python_reg_expressions.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004-959-559 # This is Phone Number\n"
     ]
    }
   ],
   "source": [
    "# here is a sample data\n",
    "phone = \"2004-959-559 # This is Phone Number\"\n",
    "\n",
    "print(phone)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's use regular expression to search a pattern of strings or to manipulate the original texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004-959-559 \n"
     ]
    }
   ],
   "source": [
    "# Delete Python-style comments #.*$ means removing \"# and the rest of the strings\" \n",
    "# $ Matches the end of the string.\n",
    "\n",
    "num = re.sub('#.*$', \"\", phone)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004-959-559 \n"
     ]
    }
   ],
   "source": [
    "num = re.sub('#.*', \"\", phone)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004-959-559 \n"
     ]
    }
   ],
   "source": [
    "phone2 = \"2004-959-559 # This is Phone Number. Another phone number is 1234-2698\"\n",
    "num = re.sub('#.*$', \"\", phone2)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004-959-559  Another phone number is 1234-2698\n"
     ]
    }
   ],
   "source": [
    "num = re.sub('#.*\\.', \"\", phone2)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004959559\n"
     ]
    }
   ],
   "source": [
    "# Remove anything other than digits ... \\D means removing \"any nondigits\"\n",
    "phone = \"2004-959-559 # This is Phone Number\"\n",
    "num = re.sub('\\D', \"\", phone)    \n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency0.tsv\n"
     ]
    }
   ],
   "source": [
    "# another sample data to rename text file\n",
    "filename = \"frequency0.tsv\"\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# renaming file\n",
    "newname = re.sub('\\D', \"\", filename)    \n",
    "print(newname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.\n"
     ]
    }
   ],
   "source": [
    "newname = re.sub('[a-z]', \"\", filename)    \n",
    "print(newname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency0.tsv\n"
     ]
    }
   ],
   "source": [
    "newname = re.sub('[A-Z]', \"\", filename)    \n",
    "print(newname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency.tsv\n"
     ]
    }
   ],
   "source": [
    "# renaming without numbers\n",
    "newname = re.sub('\\d', \"\", filename)    \n",
    "print(newname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.tsv\n"
     ]
    }
   ],
   "source": [
    "newname = filename[9:]  \n",
    "print(newname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency\n"
     ]
    }
   ],
   "source": [
    "newname = re.sub('\\d.*', \"\", filename)    \n",
    "print(newname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency.tsv\n"
     ]
    }
   ],
   "source": [
    "newname = re.sub('[0-9]', \"\", filename)    \n",
    "print(newname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency.tsv\n"
     ]
    }
   ],
   "source": [
    "# Remove useless numbers and alphanumerical words\n",
    "newname = re.sub('[A-Z0-9]', \"\", filename)\n",
    "print(newname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @mike: #big data is great #bigdata  @Cernovich @michaelmalice #ibm visit for latest reports, excellent, call 123-3698!\n"
     ]
    }
   ],
   "source": [
    "x = 'RT @mike: #big data is great #bigdata  @Cernovich @michaelmalice #ibm visit for latest reports, excellent, call 123-3698!'\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " '@mike:',\n",
       " '#big',\n",
       " 'data',\n",
       " 'is',\n",
       " 'great',\n",
       " '#bigdata',\n",
       " '@Cernovich',\n",
       " '@michaelmalice',\n",
       " '#ibm',\n",
       " 'visit',\n",
       " 'for',\n",
       " 'latest',\n",
       " 'reports,',\n",
       " 'excellent,',\n",
       " 'call',\n",
       " '123-3698!']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " 'mike',\n",
       " 'big',\n",
       " 'data',\n",
       " 'is',\n",
       " 'great',\n",
       " 'bigdata',\n",
       " 'Cernovich',\n",
       " 'michaelmalice',\n",
       " 'ibm',\n",
       " 'visit',\n",
       " 'for',\n",
       " 'latest',\n",
       " 'reports',\n",
       " 'excellent',\n",
       " 'call',\n",
       " '123',\n",
       " '3698',\n",
       " '']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization\n",
    "# \\W Matches any character that is not a word character (alphanumeric & underscore).\n",
    "\n",
    "re.split('\\W+', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expression for Text Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I love this sandwich!!!! Call at 123456789 for free sandwiches', 'this is an amazing place! But very expensive', 'I feel very good about these beers.', 'this is my best work ^-^', 'what an awesome view visit here zip code 12345', 'I do not like this restaurant', 'I am tired of this stuff.', 'I cant deal with this', 'he is my sworn enemy!', 'my boss is horrible.', 'the beer was good.', 'I do not enjoy my job', 'I aint feeling dandy today.', 'I feel amazing!', 'Gary is a friend of mine.', 'I cant believe Im doing this.']\n"
     ]
    }
   ],
   "source": [
    "review = []\n",
    "openfile = open('data/sampledata_wordfrequency.csv', 'rt')\n",
    "r = csv.reader(openfile)\n",
    "for i in r:\n",
    "# get the first column only (ignoring the second column)\n",
    "    review.append(i[0])    \n",
    "openfile.close()\n",
    "\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love this sandwich!!!! Call at 123456789 for free sandwiches\n",
      "this is an amazing place! But very expensive\n",
      "I feel very good about these beers.\n",
      "this is my best work ^-^\n",
      "what an awesome view visit here zip code 12345\n",
      "I do not like this restaurant\n",
      "I am tired of this stuff.\n",
      "I cant deal with this\n",
      "he is my sworn enemy!\n",
      "my boss is horrible.\n",
      "the beer was good.\n",
      "I do not enjoy my job\n",
      "I aint feeling dandy today.\n",
      "I feel amazing!\n",
      "Gary is a friend of mine.\n",
      "I cant believe Im doing this.\n"
     ]
    }
   ],
   "source": [
    "for i in review:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Call'],\n",
       " ['But'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Gary'],\n",
       " ['Im']]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract every word (NOT a character) starting with a uppercase letter\n",
    "upper = []\n",
    "\n",
    "for A in review:\n",
    "    upper.append(re.findall('[A-Z]\\w+', A))\n",
    "\n",
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['love', 'this', 'sandwich', 'all', 'at', 'for', 'free', 'sandwiches'],\n",
       " ['this', 'is', 'an', 'amazing', 'place', 'ut', 'very', 'expensive'],\n",
       " ['feel', 'very', 'good', 'about', 'these', 'beers'],\n",
       " ['this', 'is', 'my', 'best', 'work'],\n",
       " ['what', 'an', 'awesome', 'view', 'visit', 'here', 'zip', 'code'],\n",
       " ['do', 'not', 'like', 'this', 'restaurant'],\n",
       " ['am', 'tired', 'of', 'this', 'stuff'],\n",
       " ['cant', 'deal', 'with', 'this'],\n",
       " ['he', 'is', 'my', 'sworn', 'enemy'],\n",
       " ['my', 'boss', 'is', 'horrible'],\n",
       " ['the', 'beer', 'was', 'good'],\n",
       " ['do', 'not', 'enjoy', 'my', 'job'],\n",
       " ['aint', 'feeling', 'dandy', 'today'],\n",
       " ['feel', 'amazing'],\n",
       " ['ary', 'is', 'friend', 'of', 'mine'],\n",
       " ['cant', 'believe', 'doing', 'this']]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract every word (NOT a character) starting with a lowercase letter\n",
    "lower = []\n",
    "\n",
    "for a in review:\n",
    "    lower.append(re.findall('[a-z]\\w+', a))\n",
    "\n",
    "lower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I                        C                                    \n",
      "                          B                 \n",
      "I                                  \n",
      "                        \n",
      "                                              \n",
      "I                            \n",
      "I                        \n",
      "I                    \n",
      "                     \n",
      "                    \n",
      "                  \n",
      "I                    \n",
      "I                          \n",
      "I              \n",
      "G                        \n",
      "I              I             \n"
     ]
    }
   ],
   "source": [
    "# extract all upper-case characters\n",
    "for i in review:\n",
    "    print(re.sub('[^A-Z]', ' ', i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  love this sandwich      all at           for free sandwiches\n",
      "this is an amazing place   ut very expensive\n",
      "  feel very good about these beers \n",
      "this is my best work    \n",
      "what an awesome view visit here zip code      \n",
      "  do not like this restaurant\n",
      "  am tired of this stuff \n",
      "  cant deal with this\n",
      "he is my sworn enemy \n",
      "my boss is horrible \n",
      "the beer was good \n",
      "  do not enjoy my job\n",
      "  aint feeling dandy today \n",
      "  feel amazing \n",
      " ary is a friend of mine \n",
      "  cant believe  m doing this \n"
     ]
    }
   ],
   "source": [
    "# replace non lowercase words with empty\n",
    "for i in review:\n",
    "    print(re.sub('[^a-z]', ' ', i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 123456789                    \n",
      "                                            \n",
      "                                   \n",
      "                        \n",
      "                                         12345\n",
      "                             \n",
      "                         \n",
      "                     \n",
      "                     \n",
      "                    \n",
      "                  \n",
      "                     \n",
      "                           \n",
      "               \n",
      "                         \n",
      "                             \n"
     ]
    }
   ],
   "source": [
    "# extract numbers only\n",
    "for i in review:\n",
    "    print(re.sub('[^0-9]', ' ', i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love this sandwich!!!! Call at           for free sandwiches\n",
      "this is an amazing place! But very expensive\n",
      "I feel very good about these beers.\n",
      "this is my best work ^-^\n",
      "what an awesome view visit here zip code      \n",
      "I do not like this restaurant\n",
      "I am tired of this stuff.\n",
      "I cant deal with this\n",
      "he is my sworn enemy!\n",
      "my boss is horrible.\n",
      "the beer was good.\n",
      "I do not enjoy my job\n",
      "I aint feeling dandy today.\n",
      "I feel amazing!\n",
      "Gary is a friend of mine.\n",
      "I cant believe Im doing this.\n"
     ]
    }
   ],
   "source": [
    "# remove numbers:\n",
    "\n",
    "for i in review:\n",
    "    print(re.sub('[0-9]', ' ', i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love this sandwich     Call at           for free sandwiches\n",
      "this is an amazing place  But very expensive\n",
      "I feel very good about these beers \n",
      "this is my best work    \n",
      "what an awesome view visit here zip code      \n",
      "I do not like this restaurant\n",
      "I am tired of this stuff \n",
      "I cant deal with this\n",
      "he is my sworn enemy \n",
      "my boss is horrible \n",
      "the beer was good \n",
      "I do not enjoy my job\n",
      "I aint feeling dandy today \n",
      "I feel amazing \n",
      "Gary is a friend of mine \n",
      "I cant believe Im doing this \n"
     ]
    }
   ],
   "source": [
    "# extract alphabetical letters\n",
    "for i in review:\n",
    "    print(re.sub('[^a-zA-Z]', ' ', i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'this', 'sandwich', 'Call', 'at', 'for', 'free', 'sandwiches']\n",
      "['this', 'is', 'an', 'amazing', 'place', 'But', 'very', 'expensive']\n",
      "['I', 'feel', 'very', 'good', 'about', 'these', 'beers']\n",
      "['this', 'is', 'my', 'best', 'work']\n",
      "['what', 'an', 'awesome', 'view', 'visit', 'here', 'zip', 'code']\n",
      "['I', 'do', 'not', 'like', 'this', 'restaurant']\n",
      "['I', 'am', 'tired', 'of', 'this', 'stuff']\n",
      "['I', 'cant', 'deal', 'with', 'this']\n",
      "['he', 'is', 'my', 'sworn', 'enemy']\n",
      "['my', 'boss', 'is', 'horrible']\n",
      "['the', 'beer', 'was', 'good']\n",
      "['I', 'do', 'not', 'enjoy', 'my', 'job']\n",
      "['I', 'aint', 'feeling', 'dandy', 'today']\n",
      "['I', 'feel', 'amazing']\n",
      "['Gary', 'is', 'a', 'friend', 'of', 'mine']\n",
      "['I', 'cant', 'believe', 'Im', 'doing', 'this']\n"
     ]
    }
   ],
   "source": [
    "# extract alphabetical letters and tokenize\n",
    "for i in review:\n",
    "    data = re.sub('[^a-zA-Z]', ' ', i)\n",
    "    print(data.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For complex regular expressions, you would post questions on Stackoverflow ^-^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An Example**\n",
    "\n",
    "- A stackoverflow question (https://stackoverflow.com/questions/12683201/python-re-split-to-split-by-spaces-commas-and-periods-but-not-in-cases-like)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "I want to use python re.split() to split a string into individual words by spaces, commas and periods. But I don't want \"1,200\" to be split into [\"1\", \"200\"] or [\"1.2\"] to be split into [\"1\", \"2\"].\n",
    "\n",
    "Example\n",
    "\n",
    "l = \"one two 3.4 5,6 seven.eight nine,ten\"\n",
    "The result should be [\"one\", \"two\", \"3.4\", \"5,6\" , \"seven\", \"eight\", \"nine\", \"ten\"]\n",
    "\n",
    "Answer:\n",
    "\n",
    "Use a negative lookahead and a negative lookbehind:\n",
    "\n",
    "> s = \"one two 3.4 5,6 seven.eight nine,ten\"\n",
    "> parts = re.split('\\s|(?<!\\d)[,.](?!\\d)', s)\n",
    "['one', 'two', '3.4', '5,6', 'seven', 'eight', 'nine', 'ten']\n",
    "In other words, you always split by \\s (whitespace), and only split by commas and periods if they are not followed (?!\\d) or preceded (?<!\\d) by a digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one two 3.4 5,6 seven.eight nine,ten\n"
     ]
    }
   ],
   "source": [
    "x = \"one two 3.4 5,6 seven.eight nine,ten\"\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'two', '3.4', '5,6', 'seven', 'eight', 'nine', 'ten']\n"
     ]
    }
   ],
   "source": [
    "parts = re.split('\\s|(?<!\\d)[,.](?!\\d)', x)\n",
    "print(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'two', '3.4', '5,6', 'seven', 'eight', 'nine', 'ten']\n"
     ]
    }
   ],
   "source": [
    "parts = re.split(\" |(?<![0-9])[.,](?![0-9])\", x)\n",
    "print(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- http://www.codeproject.com/Articles/9099/The-30-Minute-Regex-Tutorial\n",
    "- http://www.tutorialspoint.com/python/python_reg_expressions.htm\n",
    "- https://regexr.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
